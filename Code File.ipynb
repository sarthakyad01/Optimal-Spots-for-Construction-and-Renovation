{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6AfAimExEUt"
      },
      "outputs": [],
      "source": [
        "#get the csv file into the notebook\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tMgHrFBxHG8"
      },
      "outputs": [],
      "source": [
        "#Package imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas.plotting import scatter_matrix\n",
        "from numpy import arange\n",
        "from pandas import read_table\n",
        "from pandas import set_option\n",
        "from pandas.plotting import scatter_matrix\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.patches as mpatches\n",
        "import plotly.express as px\n",
        "from sklearn.cluster import KMeans\n",
        "import mpl_toolkits.mplot3d\n",
        "from sklearn import datasets\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import graphviz\n",
        "%matplotlib inline\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from sklearn.model_selection import train_test_split, cross_val_score,GridSearchCV\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df='providers.csv'"
      ],
      "metadata": {
        "id": "GgJJVLl5HTBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OOUn-jkxHOm"
      },
      "outputs": [],
      "source": [
        "#Read the training dataframe as a csv\n",
        "df=pd.read_csv('CensusCanada2021Training.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.mean(df)\n",
        "std = np.std(df)\n",
        "z_scores = (df - mean) / std\n",
        "mean"
      ],
      "metadata": {
        "id": "TTH6QzsYt1Vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81RFu96N7GVu"
      },
      "source": [
        "#Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_4ybJY2IOWN"
      },
      "outputs": [],
      "source": [
        "#Look at the number of rows and columns in the dataframe\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZnicmnLxHRn"
      },
      "outputs": [],
      "source": [
        "#Provide information on the variables in the dataframe\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_elOB1W2Fxnt"
      },
      "outputs": [],
      "source": [
        "#Provide summary statistics for all the variables in the dataframe\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UT2rBWezF1rc"
      },
      "outputs": [],
      "source": [
        "#Type of columns in the dataframe\n",
        "df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlX0K76ZF5Li"
      },
      "outputs": [],
      "source": [
        "#Percentage of null values in each of the variables in the dataframe\n",
        "round((df.isna().sum()/df.shape[0])*100,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uET9hNR0WwR"
      },
      "outputs": [],
      "source": [
        "#Check if there are any observations in which all rows have null values, these rows will be dropped\n",
        "df.isnull().all(axis=0).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4F8AHyLF7Cq"
      },
      "outputs": [],
      "source": [
        "#Determine if there are any whitespaces in the columns of the dataframe\n",
        "whitespace_count = {}\n",
        "for i in df.columns:\n",
        "  whitespace_count[i] = round(df[i].apply(lambda x: isinstance(x, str) and x.isspace()).sum()/df.shape[0],4)*100\n",
        "whitespace_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOM4Z57cx_E9"
      },
      "outputs": [],
      "source": [
        "#Make a copy of the original dataframe to avoid direct manipulation of the original data\n",
        "df1=df.copy()\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mrnr2B-ezuT0"
      },
      "outputs": [],
      "source": [
        "#Verify the dataframe was correctly copied\n",
        "print(df1.columns)\n",
        "print(df1.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA2g0TuXU8hT"
      },
      "source": [
        "##Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpR_EpUJH1UY"
      },
      "outputs": [],
      "source": [
        "#Impute missing values for Total Households column\n",
        "counts_hs=df1['Total Households'].dropna().value_counts(normalize=True)\n",
        "def dist_nan(series, value_counts):\n",
        "    mask = series.isna()\n",
        "    imputed_values = np.random.choice(value_counts.index, size=mask.sum(), p=value_counts.values)\n",
        "    series[mask] = imputed_values\n",
        "    return series\n",
        "df1['Total Households']=dist_nan(df1['Total Households'].copy(),counts_hs)\n",
        "df1['Total Households'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4uRVpZ5xz7x"
      },
      "outputs": [],
      "source": [
        "#Impute missing values for Total Households For Period Of Construction\n",
        "counts_totpc=df1['Total Households For Period Of Construction'].dropna().value_counts(normalize=True)\n",
        "df1['Total Households For Period Of Construction']=dist_nan(df1['Total Households For Period Of Construction'].copy(),counts_totpc)\n",
        "df1['Total Households For Period Of Construction'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf6RFTKXx3aB"
      },
      "outputs": [],
      "source": [
        "#Impute missing values for Total Households For Period Of Construction Built Before 1961\n",
        "counts_totpc61=df1['Total Households For Period Of Construction Built Before 1961'].dropna().value_counts(normalize=True)\n",
        "df1['Total Households For Period Of Construction Built Before 1961']=dist_nan(df1['Total Households For Period Of Construction Built Before 1961'].copy(),counts_totpc61)\n",
        "df1['Total Households For Period Of Construction Built Before 1961'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsFMLa4YzUaL"
      },
      "outputs": [],
      "source": [
        "#Impute missing values for Total Households For Period Of Construction Built Between 1961 And 1980\n",
        "counts_totpc80=df1['Total Households For Period Of Construction Built Between 1961 And 1980'].dropna().value_counts(normalize=True)\n",
        "df1['Total Households For Period Of Construction Built Between 1961 And 1980']=dist_nan(df1['Total Households For Period Of Construction Built Between 1961 And 1980'].copy(),counts_totpc80)\n",
        "df1['Total Households For Period Of Construction Built Between 1961 And 1980'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1mV8_a8zkUT"
      },
      "outputs": [],
      "source": [
        "#Rename the column in a manner appropriate based on the names of the other columns in the dataframe\n",
        "df1=df1.rename(columns={'Total Households For Period Of Construction Built Between 1981 And 190':'Total Households For Period Of Construction Built Between 1981 And 1990'})\n",
        "df1.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4j7MzS5X00Pv"
      },
      "outputs": [],
      "source": [
        "#Impute missing values for Total Households For Period Of Construction Built Between 1981 And 1990\n",
        "counts_totpc90=df1['Total Households For Period Of Construction Built Between 1981 And 1990'].dropna().value_counts(normalize=True)\n",
        "df1['Total Households For Period Of Construction Built Between 1981 And 1990']=dist_nan(df1['Total Households For Period Of Construction Built Between 1981 And 1990'].copy(),counts_totpc90)\n",
        "df1['Total Households For Period Of Construction Built Between 1981 And 1990'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DezkiMTh1Tht"
      },
      "outputs": [],
      "source": [
        "#Impute missing values for Total Households For Period Of Construction Built Between 1991 And 2000\n",
        "counts_totpc00=df1['Total Households For Period Of Construction Built Between 1991 And 2000'].dropna().value_counts(normalize=True)\n",
        "df1['Total Households For Period Of Construction Built Between 1991 And 2000']=dist_nan(df1['Total Households For Period Of Construction Built Between 1991 And 2000'].copy(),counts_totpc00)\n",
        "df1['Total Households For Period Of Construction Built Between 1991 And 2000'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78eQAuCN1i00"
      },
      "outputs": [],
      "source": [
        "#Impute missing values for Total Households For Period Of Construction Built Between 2001 And 2005\n",
        "counts_totpc05=df1['Total Households For Period Of Construction Built Between 2001 And 2005'].dropna().value_counts(normalize=True)\n",
        "df1['Total Households For Period Of Construction Built Between 2001 And 2005']=dist_nan(df1['Total Households For Period Of Construction Built Between 2001 And 2005'].copy(),counts_totpc05)\n",
        "df1['Total Households For Period Of Construction Built Between 2001 And 2005'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHqE2ORD1y0e"
      },
      "outputs": [],
      "source": [
        "#Impute missing values for Total Households For Period Of Construction Built Between 2006 And 2010\n",
        "counts_totpc10=df1['Total Households For Period Of Construction Built Between 2006 And 2010'].dropna().value_counts(normalize=True)\n",
        "df1['Total Households For Period Of Construction Built Between 2006 And 2010']=dist_nan(df1['Total Households For Period Of Construction Built Between 2006 And 2010'].copy(),counts_totpc10)\n",
        "df1['Total Households For Period Of Construction Built Between 2006 And 2010'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjayqAcz2NIP"
      },
      "outputs": [],
      "source": [
        "#Impute missing values for Total Households For Period Of Construction Built Between 2011 And 2015\n",
        "counts_totpc15=df1['Total Households For Period Of Construction Built Between 2011 And 2015'].dropna().value_counts(normalize=True)\n",
        "df1['Total Households For Period Of Construction Built Between 2011 And 2015']=dist_nan(df1['Total Households For Period Of Construction Built Between 2011 And 2015'].copy(),counts_totpc15)\n",
        "df1['Total Households For Period Of Construction Built Between 2011 And 2015'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NnHaSF12dV0"
      },
      "outputs": [],
      "source": [
        "#Impute missing values for Total Households For Period Of Construction Built Between 2016 And 2021\n",
        "counts_totpc21=df1['Total Households For Period Of Construction Built Between 2016 And 2021'].dropna().value_counts(normalize=True)\n",
        "df1['Total Households For Period Of Construction Built Between 2016 And 2021']=dist_nan(df1['Total Households For Period Of Construction Built Between 2016 And 2021'].copy(),counts_totpc21)\n",
        "df1['Total Households For Period Of Construction Built Between 2016 And 2021'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8AoHpDA3OzM"
      },
      "outputs": [],
      "source": [
        "#Impute missing values for Total Households for Tenure\n",
        "counts_tothst=df1['Total Households for Tenure'].dropna().value_counts(normalize=True)\n",
        "df1['Total Households for Tenure']=dist_nan(df1['Total Households for Tenure'].copy(),counts_tothst)\n",
        "df1['Total Households for Tenure'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qVE2GsW3co1"
      },
      "outputs": [],
      "source": [
        "#Impute missing values for Dwellings by Tenure Owner\n",
        "counts_dwto=df1['Dwellings by Tenure Owner'].dropna().value_counts(normalize=True)\n",
        "df1['Dwellings by Tenure Owner']=dist_nan(df1['Dwellings by Tenure Owner'].copy(),counts_dwto)\n",
        "df1['Dwellings by Tenure Owner'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUbZUej93rjb"
      },
      "outputs": [],
      "source": [
        "#Impute missing values for Dwellings by Tenure Renter\n",
        "counts_dwtr=df1['Dwellings by Tenure Renter'].dropna().value_counts(normalize=True)\n",
        "df1['Dwellings by Tenure Renter']=dist_nan(df1['Dwellings by Tenure Renter'].copy(),counts_dwtr)\n",
        "df1['Dwellings by Tenure Renter'].isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hO6PyoNrZsfJ"
      },
      "outputs": [],
      "source": [
        "#Average size of households by census tracks\n",
        "household_size=df1['Total Population']/df1['Total Households']\n",
        "household_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgO1VDK3asMx"
      },
      "outputs": [],
      "source": [
        "#Assign size of household to a variable in the dataframe\n",
        "df1['Average Household Size']=household_size\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2-5iujqa-A_"
      },
      "outputs": [],
      "source": [
        "#Proportion of Owner Dwellings\n",
        "prop_owner=df1['Dwellings by Tenure Owner']/df1['Total Households']\n",
        "prop_owner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMN1nD5wbMDb"
      },
      "outputs": [],
      "source": [
        "#Assign proportion of owners to a variable in the dataframe\n",
        "df1['Proportion Owners']=prop_owner\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSgY_W6K32yQ"
      },
      "outputs": [],
      "source": [
        "#Make another copy of the dataframe before imputing the missing values for the response variable\n",
        "df2=df1.copy()\n",
        "df2.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEFB3nOC4v09"
      },
      "outputs": [],
      "source": [
        "#Using a linear regression model to impute the values of the response variable\n",
        "training_dat=df2[df2['Median Household Income (Current Year $)'].notna()]\n",
        "predicting_dat=df2[df2['Median Household Income (Current Year $)'].isna()]\n",
        "model=LinearRegression()\n",
        "model.fit(training_dat.drop('Median Household Income (Current Year $)',axis=1),training_dat['Median Household Income (Current Year $)'])\n",
        "predicted_values = model.predict(predicting_dat.drop('Median Household Income (Current Year $)',axis=1))\n",
        "df2.loc[df2['Median Household Income (Current Year $)'].isna(), 'Median Household Income (Current Year $)'] = predicted_values\n",
        "#Verifying all missing values have been removed from the dataframe\n",
        "df2.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cDEqcitA-RmM"
      },
      "outputs": [],
      "source": [
        "#Normalizing the dataframe to avoid any bias when applying clustering algorithm\n",
        "col_df2=df2.columns\n",
        "scaler=StandardScaler()\n",
        "arr2=scaler.fit_transform(df2)\n",
        "df2=pd.DataFrame(arr2, columns=col_df2)\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2DX5HMX7DE6"
      },
      "source": [
        "#EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "il-TOpvIUrt4"
      },
      "outputs": [],
      "source": [
        "#Summary statistics for final cleaned normalized data\n",
        "df2.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeZ1fwQ17D2d"
      },
      "outputs": [],
      "source": [
        "#Correlation between the different variables in the dataframe\n",
        "df2.corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4o-onfZ73-a"
      },
      "outputs": [],
      "source": [
        "# Correlation analysis, focusing on 'Median Household Income'\n",
        "correlation_matrix = df2.corr()\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajYbebAuElZ8"
      },
      "outputs": [],
      "source": [
        "# Selecting a subset of columns for EDA\n",
        "columns_for_eda = df2.columns[:10]\n",
        "df_eda = df2[columns_for_eda]\n",
        "\n",
        "# Outlier Detection using boxplots\n",
        "plt.figure(figsize=(30, 10))\n",
        "for i, col in enumerate(df_eda.columns):\n",
        "    plt.subplot(3, 4, i + 1)\n",
        "    sns.boxplot(y=df_eda[col])\n",
        "    plt.title(f'Boxplot of {col}')\n",
        "    plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0hxUEz5n648"
      },
      "outputs": [],
      "source": [
        "# Feature Distribution Analysis using histograms for a subset of columns\n",
        "df_eda.hist(bins=15, figsize=(30, 10), layout=(3, 4))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jgmCtthnkn3"
      },
      "outputs": [],
      "source": [
        "#Selecting the remaining columns for EDA\n",
        "columns_for_eda = df2.columns[10:]\n",
        "df_eda = df2[columns_for_eda]\n",
        "\n",
        "# Outlier Detection using boxplots\n",
        "plt.figure(figsize=(30, 10))\n",
        "for i, col in enumerate(df_eda.columns):\n",
        "    plt.subplot(3, 4, i + 1)\n",
        "    sns.boxplot(y=df_eda[col])\n",
        "    plt.title(f'Boxplot of {col}')\n",
        "    plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ojHg5ZklElJu"
      },
      "outputs": [],
      "source": [
        "# Feature Distribution Analysis using histograms for the remaining columns\n",
        "df_eda.hist(bins=15, figsize=(30, 10), layout=(3, 4))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gh41Y0besvu4"
      },
      "outputs": [],
      "source": [
        "#Density Plots for all the variables in the dataframe\n",
        "sns.set(style='whitegrid')\n",
        "for i in df2.columns:\n",
        "  plt.figure(figsize=(30,10))\n",
        "  sns.kdeplot(df2[i], label=i)\n",
        "  plt.title(f'Density plot of {i}')\n",
        "  plt.xlabel(i)\n",
        "  plt.ylabel('Density')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5vS7DSmoiVG"
      },
      "outputs": [],
      "source": [
        "#Make a scatter matrix for the cleaned dataframe\n",
        "scatter_matrix(df2, alpha=0.2, figsize=(50,10), diagonal='hist')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Py7Bj9IvptZH"
      },
      "outputs": [],
      "source": [
        "#Outlier detection in the normalized dataframe such that if any of the variable values are above the threshold then the observation is considered an outlier\n",
        "threshold=3\n",
        "outliers=(abs(df2)>threshold).any(axis=1)\n",
        "outlier_vals=df2[outliers]\n",
        "outlier_vals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCVLvlYhwO4M"
      },
      "outputs": [],
      "source": [
        "#A series of pairplots with regression lines for pairs of variables in the dataframe to identify relationships\n",
        "plt.figure(figsize=(40,10))\n",
        "sns.pairplot(df2,kind='reg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6H63BsF4iQW"
      },
      "source": [
        "#Feature Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPFksWYF5Elz"
      },
      "source": [
        "##Decision Tree Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtuUuzPQ522Z"
      },
      "outputs": [],
      "source": [
        "#Importing the packages\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "#Creating predictor and response variables\n",
        "X=df2.drop('Median Household Income (Current Year $)',axis=1)\n",
        "y=df2['Median Household Income (Current Year $)']\n",
        "#Train test split of the predictor and response variable\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "#Initialize Decision Tree Regressor\n",
        "tree = DecisionTreeRegressor(random_state=42)\n",
        "#Fit the decision tree\n",
        "tree.fit(X_train, y_train)\n",
        "#Identify feature importance\n",
        "feature_importances = pd.Series(tree.feature_importances_, index=X.columns)\n",
        "#Sort the feature importance in descending order for the predictor variables\n",
        "sorted_features = feature_importances.sort_values(ascending=False)\n",
        "sorted_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8gORnza8pkY"
      },
      "outputs": [],
      "source": [
        "#Feature importance plot based on the Decision Tree\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=sorted_features.values, y=sorted_features.index)\n",
        "plt.xlabel('Importance of the Feature')\n",
        "plt.ylabel('Features Present')\n",
        "plt.title('Feature Importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXcI2rhk98x9"
      },
      "source": [
        "##Principal Component Analysis for Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sghUm4Zt9DEV"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "#Using the Median Household Income variables as the response variable\n",
        "X=df2.drop('Median Household Income (Current Year $)',axis=1)\n",
        "y=df2['Median Household Income (Current Year $)']\n",
        "#Performing PCA analysis on the predictor variables considering Median Household Income as the response variable\n",
        "pca=PCA()\n",
        "X1=pca.fit_transform(X)\n",
        "pca_df = pd.DataFrame(data=X1, columns=[f'PC{i+1}' for i in range(len(X.columns))])\n",
        "#How many variables explain the variance for the response variable\n",
        "exp_var = pca.explained_variance_ratio_\n",
        "#Plotting the results of the Principal Component Analysis as a barplot\n",
        "plt.figure(figsize=(20, 10))\n",
        "plt.bar(range(1, len(exp_var) + 1), exp_var, alpha=0.5, align='center',label='individual explained variance')\n",
        "plt.ylabel('Explained variance ratio')\n",
        "plt.xlabel('Principal component index')\n",
        "plt.legend(loc='best')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uelH2Nyz-eHX"
      },
      "outputs": [],
      "source": [
        "#Loading which variables are most important based for the Principal Component Index considered\n",
        "loadings = pca.components_\n",
        "loadings_df = pd.DataFrame(loadings.T, columns=[f'PC{i+1}' for i in range(len(X.columns))], index=X.columns)\n",
        "loadings_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4e9-IUD3EsmX"
      },
      "outputs": [],
      "source": [
        "#Dropping the variables Dwellings by Tenure Owner, Dwellings by Tenure Renter, Total Households for Tenure, Total Households, Total Households For Period Of Construction\n",
        "df2_sub=df2.drop(columns=['Dwellings by Tenure Owner','Dwellings by Tenure Renter','Total Households for Tenure', 'Total Households','Total Households For Period Of Construction','Total Households For Structure Type Houses'],axis=1)\n",
        "df2_sub.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yl-r9ct9G8U1"
      },
      "outputs": [],
      "source": [
        "#Information on the dataframe to be used for modelling\n",
        "df2_sub.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lu6DZaUgHmWK"
      },
      "outputs": [],
      "source": [
        "#Shape of the final dataframe to be used for modelling\n",
        "df2_sub.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25r7YhauH6nw"
      },
      "outputs": [],
      "source": [
        "#Performing Decision Tree Feature Selection on the subsetted data\n",
        "X=df2_sub.drop('Median Household Income (Current Year $)',axis=1)\n",
        "y=df2_sub['Median Household Income (Current Year $)']\n",
        "#Train test split of the predictor and response variable\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "#Initialize Decision Tree Regressor\n",
        "tree = DecisionTreeRegressor(random_state=42)\n",
        "#Fit the decision tree\n",
        "tree.fit(X_train, y_train)\n",
        "#Identify feature importance\n",
        "feature_importances = pd.Series(tree.feature_importances_, index=X.columns)\n",
        "#Sort the feature importance in descending order for the predictor variables\n",
        "sorted_features = feature_importances.sort_values(ascending=False)\n",
        "sorted_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45mLliOJIBuf"
      },
      "outputs": [],
      "source": [
        "#Feature importance plot based on the Decision Tree for the subsetted dataframe\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=sorted_features.values, y=sorted_features.index)\n",
        "plt.xlabel('Importance of the Feature')\n",
        "plt.ylabel('Features Present')\n",
        "plt.title('Feature Importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lWa1KA6BB1_"
      },
      "source": [
        "#Clustering Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yeovd88OvmB"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Assuming df2_sub is your DataFrame containing the data to be clustered\n",
        "points = df2_sub\n",
        "\n",
        "# Range of k to try\n",
        "k_values = range(1, 15)\n",
        "\n",
        "# List to store the inertia for each k\n",
        "inertia_values = []\n",
        "\n",
        "# Performing KMeans clustering for each k and storing the inertia\n",
        "for k in k_values:\n",
        "    kmeans_model = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans_model.fit(points)\n",
        "    inertia_values.append(kmeans_model.inertia_)\n",
        "\n",
        "# Plotting the Elbow graph\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(k_values, inertia_values, marker='o')\n",
        "plt.title(\"Elbow Method for Optimal k\")\n",
        "plt.xlabel(\"Number of Clusters (k)\")\n",
        "plt.ylabel(\"Inertia\")\n",
        "plt.xticks(k_values)\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Assuming df2_sub is your DataFrame containing the data to be clustered\n",
        "points = df2_sub\n",
        "\n",
        "# Range of k to try\n",
        "k_values = range(2, 7)  # Silhouette score is not defined for k = 1\n",
        "\n",
        "# List to store the silhouette scores for each k\n",
        "silhouette_scores = []\n",
        "\n",
        "# Performing KMeans clustering for each k and calculating silhouette score\n",
        "for k in k_values:\n",
        "    kmeans_model = KMeans(n_clusters=k, random_state=20)\n",
        "    cluster_labels = kmeans_model.fit_predict(points)\n",
        "    score = silhouette_score(points, cluster_labels)\n",
        "    silhouette_scores.append(score)\n",
        "\n",
        "# Plotting the silhouette scores\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(k_values, silhouette_scores, marker='o')\n",
        "plt.title(\"Silhouette Scores for Different k Values\")\n",
        "plt.xlabel(\"Number of Clusters (k)\")\n",
        "plt.ylabel(\"Silhouette Score\")\n",
        "plt.xticks(k_values)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Find the k with the highest silhouette score\n",
        "optimal_k = k_values[silhouette_scores.index(max(silhouette_scores))]\n",
        "print(f\"The optimal number of clusters, k, is: {optimal_k}\")"
      ],
      "metadata": {
        "id": "1XE0-3wMdNBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UR4BOFqZXjKA"
      },
      "outputs": [],
      "source": [
        "# Assuming df2_sub is your pandas DataFrame containing the dataset\n",
        "features = df2_sub.columns.tolist()  # This creates a list of all column names in df2_sub\n",
        "features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iueonhmi9Fnb"
      },
      "outputs": [],
      "source": [
        "# K=3 with response variable\n",
        "# Dropping the response variable to get the features\n",
        "features = ['Total Population',\n",
        " 'Median Household Income (Current Year $)',\n",
        " 'Total Households For Period Of Construction Built Before 1961',\n",
        " 'Total Households For Period Of Construction Built Between 1961 And 1980',\n",
        " 'Total Households For Period Of Construction Built Between 1981 And 1990',\n",
        " 'Total Households For Period Of Construction Built Between 1991 And 2000',\n",
        " 'Total Households For Period Of Construction Built Between 2001 And 2005',\n",
        " 'Total Households For Period Of Construction Built Between 2006 And 2010',\n",
        " 'Total Households For Period Of Construction Built Between 2011 And 2015',\n",
        " 'Total Households For Period Of Construction Built Between 2016 And 2021',\n",
        " 'Total Households For Structure Type Apartment, Building Low And High Rise',\n",
        " 'Total Households For Structure Type Other Dwelling Types','Average Household Size','Proportion Owners']\n",
        "\n",
        "\n",
        "# K-means clustering with  k = 3\n",
        "kmeans_3 = KMeans(n_clusters=3, random_state=0,n_init=100,init='random').fit(df2_sub)\n",
        "\n",
        "# Adding the cluster labels to the original dataframe\n",
        "df2_sub['Cluster_3'] = kmeans_3.labels_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dV63s7V1joKN"
      },
      "outputs": [],
      "source": [
        "# Applying PCA to reduce the dimensions to 2 for visualization\n",
        "pca_subset = PCA(n_components=2)\n",
        "features_pca_subset = pca_subset.fit_transform(df2_sub)\n",
        "\n",
        "# Adding the cluster labels to the subset dataframe\n",
        "df2_sub['Cluster_3'] = kmeans_3.labels_\n",
        "\n",
        "# Plotting for k = 3 clusters\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Plotting for k = 3 clusters\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(features_pca_subset[:, 0], features_pca_subset[:, 1], c=df2_sub['Cluster_3'], cmap='viridis', marker='o', alpha=0.5)\n",
        "plt.title('K-means Clustering with k=3 (Selected Features)')\n",
        "plt.xlabel('PCA Feature 1')\n",
        "plt.ylabel('PCA Feature 2')\n",
        "plt.colorbar(label='Cluster Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PUAkn-ToNRi"
      },
      "outputs": [],
      "source": [
        "features_pca_subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RjljQw-mX3s"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataframe for k=3 clusters\n",
        "clusters_k3 = {}\n",
        "for cluster_label in range(3):\n",
        "    clusters_k3[cluster_label] = df2_sub[df2_sub['Cluster_3'] == cluster_label]\n",
        "\n",
        "# Checking the number of records in each cluster\n",
        "num_records_k3 = {label: len(cluster) for label, cluster in clusters_k3.items()}\n",
        "num_records_k3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHJh-ehyoqQ0"
      },
      "outputs": [],
      "source": [
        "#Dataframe for first cluster when k=3\n",
        "cluster3_0=clusters_k3[0]\n",
        "cluster3_0.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jtzuoVkpIgK"
      },
      "outputs": [],
      "source": [
        "#Dataframe for second cluster when k=3\n",
        "cluster3_1=clusters_k3[1]\n",
        "cluster3_1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T89llXsG7a_p"
      },
      "outputs": [],
      "source": [
        "#Dataframe for third cluster when k=3\n",
        "cluster3_2=clusters_k3[2]\n",
        "cluster3_2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdsyA-VKpk3e"
      },
      "outputs": [],
      "source": [
        "#Get summary statistics for the first cluster dataframe when k=3\n",
        "cluster3_0.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpQ8Qf22p9H6"
      },
      "outputs": [],
      "source": [
        "#Get summary statistics for the second cluster dataframe when k=3\n",
        "cluster3_1.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RV3RkiI718D"
      },
      "outputs": [],
      "source": [
        "#Get summary statistics for the third cluster dataframe when k=3\n",
        "cluster3_2.describe()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Boxplots for all the columns in the first cluster when k=3\n",
        "sns.set(style='whitegrid')\n",
        "plt.figure(figsize=(30, 20))\n",
        "for i, column in enumerate(cluster3_0.columns, 1):\n",
        "    plt.subplot(5, 3, i)\n",
        "    sns.boxplot(y=cluster3_0[column])\n",
        "    plt.title(f'Box Plot of {column}')\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Values')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HQpYAqUCk1qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0q3pQsfOsvfF"
      },
      "outputs": [],
      "source": [
        "#Boxplots for all the columns in the second cluster when k=3\n",
        "sns.set(style='whitegrid')\n",
        "plt.figure(figsize=(30, 20))\n",
        "for i, column in enumerate(cluster3_1.columns, 1):\n",
        "    plt.subplot(5, 3, i)\n",
        "    sns.boxplot(y=cluster3_1[column])\n",
        "    plt.title(f'Box Plot of {column}')\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Values')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrundBWa8B7d"
      },
      "outputs": [],
      "source": [
        "#Boxplots for all the columns in the third cluster when k=3\n",
        "sns.set(style='whitegrid')\n",
        "plt.figure(figsize=(30, 20))\n",
        "for i, column in enumerate(cluster3_2.columns, 1):\n",
        "    plt.subplot(5, 3, i)\n",
        "    sns.boxplot(y=cluster3_2[column])\n",
        "    plt.title(f'Box Plot of {column}')\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Values')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcarOwfeti9I"
      },
      "outputs": [],
      "source": [
        "#Scatter matrix for first cluster when k=3\n",
        "plt.figure(figsize=(50,10))\n",
        "scatter_matrix(cluster3_0, alpha=0.2, figsize=(50,10), diagonal='hist')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TH2m_4CtrBr"
      },
      "outputs": [],
      "source": [
        "#Scatter matrix for second cluster when k=3\n",
        "plt.figure(figsize=(50,10))\n",
        "scatter_matrix(cluster3_1, alpha=0.2, figsize=(50,10), diagonal='hist')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EeIhn_x8Ny0"
      },
      "outputs": [],
      "source": [
        "#Scatter matrix for third cluster when k=3\n",
        "plt.figure(figsize=(50,10))\n",
        "scatter_matrix(cluster3_2, alpha=0.2, figsize=(50,10), diagonal='hist')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BG6m7deWuI_h"
      },
      "outputs": [],
      "source": [
        "#Histogram for all the columns in the first cluster when k=3\n",
        "sns.set(style='whitegrid')\n",
        "plt.figure(figsize=(25, 25))\n",
        "for i, column in enumerate(cluster3_0.columns, 1):\n",
        "    plt.subplot(5, 3, i)\n",
        "    sns.histplot(x=cluster3_0[column])\n",
        "    plt.title(f'Histogram of {column}')\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hK5svfUucWr"
      },
      "outputs": [],
      "source": [
        "#Histogram for all the columns in the second cluster when k=3\n",
        "sns.set(style='whitegrid')\n",
        "plt.figure(figsize=(25, 25))\n",
        "for i, column in enumerate(cluster3_1.columns, 1):\n",
        "    plt.subplot(5, 3, i)\n",
        "    sns.histplot(x=cluster3_1[column])\n",
        "    plt.title(f'Histogram of {column}')\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uX4f_kHk8eZ2"
      },
      "outputs": [],
      "source": [
        "#Histogram for all the columns in the third cluster when k=3\n",
        "sns.set(style='whitegrid')\n",
        "plt.figure(figsize=(25, 25))\n",
        "for i, column in enumerate(cluster3_2.columns, 1):\n",
        "    plt.subplot(5, 3, i)\n",
        "    sns.histplot(x=cluster3_2[column])\n",
        "    plt.title(f'Histogram of {column}')\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Frequency')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bo0FLRw2umdr"
      },
      "outputs": [],
      "source": [
        "#Density plots for all the variables in the first cluster when k=3\n",
        "sns.set(style='whitegrid')\n",
        "for i in cluster3_0.columns:\n",
        "  plt.figure(figsize=(30,20))\n",
        "  sns.kdeplot(x=cluster3_0[i], label=i)\n",
        "  plt.title(f'Density Plot of {i}')\n",
        "  plt.xlabel(i)\n",
        "  plt.ylabel('Density')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxcPhq3EvTi5"
      },
      "outputs": [],
      "source": [
        "#Density plots for all the variables in the second cluster when k=3\n",
        "sns.set(style='whitegrid')\n",
        "for i in cluster3_1.columns:\n",
        "  plt.figure(figsize=(30,20))\n",
        "  sns.kdeplot(x=cluster3_1[i], label=i)\n",
        "  plt.title(f'Density Plot of {i}')\n",
        "  plt.xlabel(i)\n",
        "  plt.ylabel('Density')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlQuOHEvvhCg"
      },
      "outputs": [],
      "source": [
        "#Density plots for all the variables in the third cluster when k=3\n",
        "sns.set(style='whitegrid')\n",
        "for i in cluster3_2.columns:\n",
        "  plt.figure(figsize=(30,20))\n",
        "  sns.kdeplot(x=cluster3_2[i], label=i)\n",
        "  plt.title(f'Density Plot of {i}')\n",
        "  plt.xlabel(i)\n",
        "  plt.ylabel('Density')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2T9BmswzBCmW"
      },
      "outputs": [],
      "source": [
        "#Combining all the clusters formed into a single dataframe\n",
        "df4_combined=pd.concat([cluster3_0,cluster3_1,cluster3_2], ignore_index=True)\n",
        "df4_combined.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9mssZz2OBefv"
      },
      "outputs": [],
      "source": [
        "#Draw overlapping histograms for divided by the cluster for each variable\n",
        "for column in df4_combined.columns[:-2]:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(data=df4_combined, x=column, hue='Cluster_3', multiple=\"stack\", palette=\"Set2\")\n",
        "    plt.title(f'Distribution of {column} across Clusters')\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Count')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yb93II1PCOtx"
      },
      "outputs": [],
      "source": [
        "#Draw violinplots for each variable divided by clusters\n",
        "for column in df4_combined.columns[:-2]:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.violinplot(x='Cluster_3', y=column, data=df4_combined, palette=\"Set2\")\n",
        "    plt.title(f'Distribution of {column} Across Clusters')\n",
        "    plt.xlabel('Values')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3cWDuG594Tr"
      },
      "source": [
        "#Part 2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Assuming df2_sub is your DataFrame containing the data to be clustered\n",
        "features = ['Total Population',\n",
        " 'Total Households For Period Of Construction Built Before 1961',\n",
        " 'Total Households For Period Of Construction Built Between 1961 And 1980',\n",
        " 'Total Households For Period Of Construction Built Between 1981 And 1990',\n",
        " 'Total Households For Period Of Construction Built Between 1991 And 2000',\n",
        " 'Total Households For Period Of Construction Built Between 2001 And 2005',\n",
        " 'Total Households For Period Of Construction Built Between 2006 And 2010',\n",
        " 'Total Households For Period Of Construction Built Between 2011 And 2015',\n",
        " 'Total Households For Period Of Construction Built Between 2016 And 2021',\n",
        " 'Total Households For Structure Type Apartment, Building Low And High Rise',\n",
        " 'Total Households For Structure Type Other Dwelling Types','Average Household Size','Proportion Owners']\n",
        "points = df2_sub[features]\n",
        "\n",
        "# Range of k to try\n",
        "k_values = range(1, 15)\n",
        "\n",
        "# List to store the inertia for each k\n",
        "inertia_values = []\n",
        "\n",
        "# Performing KMeans clustering for each k and storing the inertia\n",
        "for k in k_values:\n",
        "    kmeans_model = KMeans(n_clusters=k, random_state=42,n_init=100,init='random')\n",
        "    kmeans_model.fit(points)\n",
        "    inertia_values.append(kmeans_model.inertia_)\n",
        "\n",
        "# Plotting the Elbow graph\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(k_values, inertia_values, marker='o')\n",
        "plt.title(\"Elbow Method for Optimal k\")\n",
        "plt.xlabel(\"Number of Clusters (k)\")\n",
        "plt.ylabel(\"Inertia\")\n",
        "plt.xticks(k_values)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sL6B9OaBZgK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAESBsNu8vs9"
      },
      "outputs": [],
      "source": [
        "# K=3 without response variable\n",
        "# Dropping the response variable to get the features\n",
        "features = ['Total Population',\n",
        " 'Total Households For Period Of Construction Built Before 1961',\n",
        " 'Total Households For Period Of Construction Built Between 1961 And 1980',\n",
        " 'Total Households For Period Of Construction Built Between 1981 And 1990',\n",
        " 'Total Households For Period Of Construction Built Between 1991 And 2000',\n",
        " 'Total Households For Period Of Construction Built Between 2001 And 2005',\n",
        " 'Total Households For Period Of Construction Built Between 2006 And 2010',\n",
        " 'Total Households For Period Of Construction Built Between 2011 And 2015',\n",
        " 'Total Households For Period Of Construction Built Between 2016 And 2021',\n",
        " 'Total Households For Structure Type Apartment, Building Low And High Rise',\n",
        " 'Total Households For Structure Type Other Dwelling Types','Average Household Size','Proportion Owners']\n",
        "\n",
        "\n",
        "# K-means clustering with k = 3\n",
        "kmeans_3_model = KMeans(n_clusters=3, random_state=0,n_init=100,init='random')\n",
        "kmeans_3=kmeans_3_model.fit(df2_sub)\n",
        "\n",
        "# Adding the cluster labels to the original dataframe\n",
        "df2_sub['Cluster_3'] = kmeans_3.labels_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C24hsLGi_H4r"
      },
      "outputs": [],
      "source": [
        "# Applying PCA to reduce the dimensions to 2 for visualization\n",
        "pca_subset = PCA(n_components=2)\n",
        "features_pca_subset = pca_subset.fit_transform(df2_sub)\n",
        "\n",
        "# Adding the cluster labels to the subset dataframe\n",
        "df2_sub['Cluster_3'] = kmeans_3.labels_\n",
        "\n",
        "# Plotting for k = 2 clusters\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(features_pca_subset[:, 0], features_pca_subset[:, 1], c=df2_sub['Cluster_3'], cmap='viridis', marker='o', alpha=0.5)\n",
        "plt.title('K-means Clustering with k=3 (Selected Features)')\n",
        "plt.xlabel('PCA Feature 1')\n",
        "plt.ylabel('PCA Feature 2')\n",
        "plt.colorbar(label='Cluster Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQQ1NtA92T-U"
      },
      "outputs": [],
      "source": [
        "features_pca_subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "946nUgeB_8r-"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataframe for k=3 clusters\n",
        "clusters_k3 = {}\n",
        "for cluster_label in range(3):\n",
        "    clusters_k3[cluster_label] = df2_sub[df2_sub['Cluster_3'] == cluster_label]\n",
        "\n",
        "# Checking the number of records in each cluster for k=3\n",
        "num_records_k3 = {label: len(cluster) for label, cluster in clusters_k3.items()}\n",
        "num_records_k3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVs_dBJAJgRm"
      },
      "outputs": [],
      "source": [
        "clusters_k3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2OstLWdTiv3"
      },
      "outputs": [],
      "source": [
        "cluster3_0=clusters_k3[0]\n",
        "cluster3_1=clusters_k3[1]\n",
        "cluster3_2=clusters_k3[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edK4-ioSGbVo"
      },
      "outputs": [],
      "source": [
        "#Combining the clustered dataframes into a single dataframe\n",
        "fullcluster3=pd.concat([cluster3_0,cluster3_1,cluster3_2]).sort_index()\n",
        "fullcluster3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4vUj0HGGkCg"
      },
      "outputs": [],
      "source": [
        "#Boxplot for Median Household Income by cluster\n",
        "sns.boxplot(x='Cluster_3', y='Median Household Income (Current Year $)', data=fullcluster3, palette=\"Set2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iY1zVm6nHGbP"
      },
      "outputs": [],
      "source": [
        "#Boxplot for Houses constructed from 1961-1980 by cluster\n",
        "sns.boxplot(x='Cluster_3', y='Total Households For Period Of Construction Built Between 1961 And 1980', data=fullcluster3, palette=\"Set2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjnW72GpGE0F"
      },
      "outputs": [],
      "source": [
        "#Converting Median Household Income to non-z score values for cluster label 0\n",
        "ser=(cluster3_0['Median Household Income (Current Year $)']*25000)+80000\n",
        "sns.boxplot(y=ser)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTpKp-PDGILa"
      },
      "outputs": [],
      "source": [
        "#Converting Median Household Income to non-z score values for cluster label 1\n",
        "ser1=(cluster3_1['Median Household Income (Current Year $)']*25000)+80000\n",
        "sns.boxplot(y=ser1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFgY11PeGV8I"
      },
      "outputs": [],
      "source": [
        "#Converting Median Household Income to non-z score values for cluster label 2\n",
        "ser2=(cluster3_2['Median Household Income (Current Year $)']*25000)+80000\n",
        "sns.boxplot(y=ser2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf3UcLnsUX3j"
      },
      "source": [
        "## linear regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCkjstKlFNop"
      },
      "outputs": [],
      "source": [
        "#Linear regression on the first cluster for best clustering model when Median Household Income is the response variable\n",
        "X=cluster3_0.drop(['Cluster_3','Median Household Income (Current Year $)'],axis=1)\n",
        "y=cluster3_0['Median Household Income (Current Year $)']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "coefficients = model.coef_\n",
        "intercept = model.intercept_\n",
        "print('Intercept:', intercept)\n",
        "print('Coefficients:', coefficients)\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "print('Training MSE:', train_mse)\n",
        "print('Training R²:', train_r2)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "print('Test MSE:', test_mse)\n",
        "print('Test R²:', test_r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yx864S1-F-ww"
      },
      "outputs": [],
      "source": [
        "#Linear regression on the second cluster for best clustering model when Median Household Income is the response variable\n",
        "X=cluster3_1.drop(['Cluster_3','Median Household Income (Current Year $)'],axis=1)\n",
        "y=cluster3_1['Median Household Income (Current Year $)']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=2)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "coefficients = model.coef_\n",
        "intercept = model.intercept_\n",
        "print('Intercept:', intercept)\n",
        "print('Coefficients:', coefficients)\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "print('Training MSE:', train_mse)\n",
        "print('Training R²:', train_r2)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "print('Test MSE:', test_mse)\n",
        "print('Test R²:', test_r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vukj-zbKGL83"
      },
      "outputs": [],
      "source": [
        "#Linear regression on the third cluster for best clustering model when Median Household Income is the response variable\n",
        "X=cluster3_2.drop(['Cluster_3','Median Household Income (Current Year $)'],axis=1)\n",
        "y=cluster3_2['Median Household Income (Current Year $)']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=3)\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "coefficients = model.coef_\n",
        "intercept = model.intercept_\n",
        "print('Intercept:', intercept)\n",
        "print('Coefficients:', coefficients)\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "print('Training MSE:', train_mse)\n",
        "print('Training R²:', train_r2)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "print('Test MSE:', test_mse)\n",
        "print('Test R²:', test_r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgy09WrOUcWP"
      },
      "source": [
        "## Polynomial regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3grEPQ1Iqj0"
      },
      "outputs": [],
      "source": [
        "#Polynomial Regression on the first cluster for the best clustering model when Median Household Income is the response variable\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "X=cluster3_0.drop(['Cluster_3','Median Household Income (Current Year $)'],axis=1)\n",
        "y=cluster3_0['Median Household Income (Current Year $)']\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.4, random_state=4)\n",
        "degree=2\n",
        "poly_features = PolynomialFeatures(degree=degree)\n",
        "X_train_poly = poly_features.fit_transform(X_train)\n",
        "X_test_poly = poly_features.transform(X_test)\n",
        "model=LinearRegression()\n",
        "model.fit(X_train_poly,y_train)\n",
        "y_pred=model.predict(X_test_poly)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "test_r2 = r2_score(y_test, y_pred)\n",
        "print('Test MSE:', mse)\n",
        "print('Test R²:', test_r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvHEgBOkJ2Dz"
      },
      "outputs": [],
      "source": [
        "#Polynomial Regression on the second cluster for the best clustering model when Median Household Income is the response variable\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "X=cluster3_1.drop(['Cluster_3','Median Household Income (Current Year $)'],axis=1)\n",
        "y=cluster3_1['Median Household Income (Current Year $)']\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.4, random_state=5)\n",
        "degree=2\n",
        "poly_features = PolynomialFeatures(degree=degree)\n",
        "X_train_poly = poly_features.fit_transform(X_train)\n",
        "X_test_poly = poly_features.transform(X_test)\n",
        "model=LinearRegression()\n",
        "model.fit(X_train_poly,y_train)\n",
        "y_pred=model.predict(X_test_poly)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "test_r2 = r2_score(y_test, y_pred)\n",
        "print('Test MSE:', mse)\n",
        "print('Test R²:', test_r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAicDyrhJ9gx"
      },
      "outputs": [],
      "source": [
        "#Polynomial Regression on the third cluster for the best clustering model when Median Household Income is the response variable\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "X=cluster3_2.drop(['Cluster_3','Median Household Income (Current Year $)'],axis=1)\n",
        "y=cluster3_2['Median Household Income (Current Year $)']\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.4, random_state=6)\n",
        "degree=2\n",
        "poly_features = PolynomialFeatures(degree=degree)\n",
        "X_train_poly = poly_features.fit_transform(X_train)\n",
        "X_test_poly = poly_features.transform(X_test)\n",
        "model=LinearRegression()\n",
        "model.fit(X_train_poly,y_train)\n",
        "y_pred=model.predict(X_test_poly)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "test_r2 = r2_score(y_test, y_pred)\n",
        "print('Test MSE:', mse)\n",
        "print('Test R²:', test_r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQODVcdUIQVx"
      },
      "source": [
        "## Random Forest\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNXQXEJtMp1a"
      },
      "outputs": [],
      "source": [
        "#Performing Random Forest on the first cluster for the best clustering model when Median Household Income is the response variable\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "X=cluster3_0.drop(['Cluster_3','Median Household Income (Current Year $)'],axis=1)\n",
        "y=cluster3_0['Median Household Income (Current Year $)']\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.4, random_state=11)\n",
        "model_rf = RandomForestRegressor(n_estimators=100)\n",
        "model_rf.fit(X_train, y_train)\n",
        "y_pred = model_rf.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print('Mean Squared Error:', mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5SQ5sqRPIaz"
      },
      "outputs": [],
      "source": [
        "#Performing Random Forest on the second cluster for the best clustering model when Median Household Income is the response variable\n",
        "X=cluster3_1.drop(['Cluster_3','Median Household Income (Current Year $)'],axis=1)\n",
        "y=cluster3_1['Median Household Income (Current Year $)']\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.4, random_state=12)\n",
        "model_rf = RandomForestRegressor(n_estimators=100)\n",
        "model_rf.fit(X_train, y_train)\n",
        "y_pred = model_rf.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print('Mean Squared Error:', mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQaSxcm2PMWm"
      },
      "outputs": [],
      "source": [
        "#Performing Random Forest on the third cluster for the best clustering model when Median Household Income is the response variable\n",
        "X=cluster3_2.drop(['Cluster_3','Median Household Income (Current Year $)'],axis=1)\n",
        "y=cluster3_2['Median Household Income (Current Year $)']\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.4, random_state=13)\n",
        "model_rf = RandomForestRegressor(n_estimators=100)\n",
        "model_rf.fit(X_train, y_train)\n",
        "y_pred = model_rf.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print('Mean Squared Error:', mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvnVblvtmRlT"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBgsZyObKoJZ"
      },
      "outputs": [],
      "source": [
        "#Performing Decision Tree on the first cluster for the best clustering model when Median Household Income is the response variable\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "X=cluster3_0.drop(['Cluster_3','Median Household Income (Current Year $)'],axis=1)\n",
        "y=cluster3_0['Median Household Income (Current Year $)']\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.4, random_state=7)\n",
        "model=DecisionTreeRegressor()\n",
        "model.fit(X_train,y_train)\n",
        "y_pred=model.predict(X_test)\n",
        "mse=mean_squared_error(y_test,y_pred)\n",
        "print('Mean Squared Error:', mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbNBe8iIL18T"
      },
      "outputs": [],
      "source": [
        "#Performing Decision Tree on the second cluster for the best clustering model when Median Household Income is the response variable\n",
        "X=cluster3_1.drop(['Cluster_3','Median Household Income (Current Year $)'],axis=1)\n",
        "y=cluster3_1['Median Household Income (Current Year $)']\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.4, random_state=8)\n",
        "model=DecisionTreeRegressor()\n",
        "model.fit(X_train,y_train)\n",
        "y_pred=model.predict(X_test)\n",
        "mse=mean_squared_error(y_test,y_pred)\n",
        "print('Mean Squared Error:', mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1p7T3y8vL6cr"
      },
      "outputs": [],
      "source": [
        "#Performing Decision Tree on the third cluster for the best clustering model when Median Household Income is the response variable\n",
        "X=cluster3_2.drop(['Cluster_3','Median Household Income (Current Year $)'],axis=1)\n",
        "y=cluster3_2['Median Household Income (Current Year $)']\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.4, random_state=9)\n",
        "model=DecisionTreeRegressor()\n",
        "model.fit(X_train,y_train)\n",
        "y_pred=model.predict(X_test)\n",
        "mse=mean_squared_error(y_test,y_pred)\n",
        "print('Mean Squared Error:', mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjorIuU_PnFQ"
      },
      "source": [
        "##Support Vector Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcWrJ3MzPt_C"
      },
      "outputs": [],
      "source": [
        "#Performing Support Vector Regression on the first cluster for the best clustering model when Median Household Income is the response variable\n",
        "from sklearn.svm import SVR\n",
        "X=cluster3_0.drop(['Cluster_3','Median Household Income (Current Year $)'],axis=1)\n",
        "y=cluster3_0['Median Household Income (Current Year $)']\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.4, random_state=22)\n",
        "model_svr = SVR(kernel='rbf', C=5,epsilon=0.5)\n",
        "model_svr.fit(X_train,y_train)\n",
        "y_pred=model_svr.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print('Mean Squared Error:', mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fioZma8xadZ7"
      },
      "outputs": [],
      "source": [
        "#Performing Support Vector Regression on the second cluster for the best clustering model when Median Household Income is the response variable\n",
        "X=cluster3_1.drop(['Cluster_3','Median Household Income (Current Year $)'],axis=1)\n",
        "y=cluster3_1['Median Household Income (Current Year $)']\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.4, random_state=23)\n",
        "model_svr = SVR(kernel='rbf', C=5,epsilon=0.5)\n",
        "model_svr.fit(X_train,y_train)\n",
        "y_pred=model_svr.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print('Mean Squared Error:', mse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vjmjfQgag6d"
      },
      "outputs": [],
      "source": [
        "#Performing Support Vector Regression on the third cluster for the best clustering model when Median Household Income is the response variable\n",
        "X=cluster3_2.drop(['Cluster_3','Median Household Income (Current Year $)'],axis=1)\n",
        "y=cluster3_2['Median Household Income (Current Year $)']\n",
        "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.4, random_state=24)\n",
        "model_svr = SVR(kernel='rbf', C=5,epsilon=0.5)\n",
        "model_svr.fit(X_train,y_train)\n",
        "y_pred=model_svr.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print('Mean Squared Error:', mse)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Dataframe"
      ],
      "metadata": {
        "id": "aH0q5iIMlFNA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9vkU-acg3uX"
      },
      "outputs": [],
      "source": [
        "#get the csv file into the notebook\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the test dataframe\n",
        "df_test=pd.read_csv('CensusCanada2021Test.csv')\n",
        "df_test.head()"
      ],
      "metadata": {
        "id": "hzKTD3HJlI44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate if there are any missing values in the dataframe\n",
        "df_test.isna().sum()"
      ],
      "metadata": {
        "id": "_LehWzkilTCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Determine if there are any whitespaces in the columns of the dataframe\n",
        "whitespace_count = {}\n",
        "for i in df_test.columns:\n",
        "  whitespace_count[i] = round(df_test[i].apply(lambda x: isinstance(x, str) and x.isspace()).sum()/df_test.shape[0],4)*100\n",
        "whitespace_count"
      ],
      "metadata": {
        "id": "0c8dfpZJtTKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rename the column in the test dataframe\n",
        "df_test=df_test.rename(columns={'Total Households For Period Of Construction Built Between 1981 And 190':'Total Households For Period Of Construction Built Between 1981 And 1990'})\n",
        "df_test.columns"
      ],
      "metadata": {
        "id": "XbN4Jb_eEuQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get information on the variables in the test dataframe\n",
        "df_test.info()"
      ],
      "metadata": {
        "id": "v9tFHKGTlbtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get summary statistics for the test dataframe\n",
        "df_test.describe()"
      ],
      "metadata": {
        "id": "MvGyql3HllIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Producing values for average household size\n",
        "household_size_test=df_test['Total Population']/df_test['Total Households']\n",
        "household_size_test"
      ],
      "metadata": {
        "id": "9b5TxUUFtuVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a new variable called Average Household Size in the dataframe\n",
        "df_test['Average Household Size']=household_size_test\n",
        "df_test.head()"
      ],
      "metadata": {
        "id": "JODxJkdOt_Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Producing values for owner proportions\n",
        "prop_owner=df_test['Dwellings by Tenure Owner']/df_test['Total Households']\n",
        "prop_owner"
      ],
      "metadata": {
        "id": "ggMFaIQ3ubkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a new variable called Proportion Owners in the dataframe\n",
        "df_test['Proportion Owners']=prop_owner\n",
        "df_test.head()"
      ],
      "metadata": {
        "id": "tAPQ_tfpupIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalizing the test dataframe to avoid any bias when applying clustering algorithm\n",
        "col_df_test=df_test.columns\n",
        "scaler=StandardScaler()\n",
        "arr_test=scaler.fit_transform(df_test)\n",
        "df_test=pd.DataFrame(arr_test, columns=col_df_test)\n",
        "df_test.head()"
      ],
      "metadata": {
        "id": "lpuqbukHlmMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping the columns based on feature analysis in the test dataframe\n",
        "df_test_sub=df_test.drop(columns=['Dwellings by Tenure Owner','Dwellings by Tenure Renter','Total Households for Tenure', 'Total Households','Total Households For Period Of Construction','Total Households For Structure Type Houses'],axis=1)\n",
        "df_test_sub.head()"
      ],
      "metadata": {
        "id": "bMYlFapovMLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Clustering on Test Data"
      ],
      "metadata": {
        "id": "gvdTM34hOrA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['Total Population',\n",
        " 'Total Households For Period Of Construction Built Before 1961',\n",
        " 'Total Households For Period Of Construction Built Between 1961 And 1980',\n",
        " 'Total Households For Period Of Construction Built Between 1981 And 1990',\n",
        " 'Total Households For Period Of Construction Built Between 1991 And 2000',\n",
        " 'Total Households For Period Of Construction Built Between 2001 And 2005',\n",
        " 'Total Households For Period Of Construction Built Between 2006 And 2010',\n",
        " 'Total Households For Period Of Construction Built Between 2011 And 2015',\n",
        " 'Total Households For Period Of Construction Built Between 2016 And 2021',\n",
        " 'Total Households For Structure Type Apartment, Building Low And High Rise',\n",
        " 'Total Households For Structure Type Other Dwelling Types','Average Household Size','Proportion Owners']\n",
        "\n",
        "\n",
        "# K-means clustering with k = 3\n",
        "kmeans_3=kmeans_3_model.fit(df_test_sub)\n",
        "\n",
        "# Adding the cluster labels to the original dataframe\n",
        "df_test_sub['Cluster_3'] = kmeans_3.labels_"
      ],
      "metadata": {
        "id": "ELY0mCZnvbnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying PCA to reduce the dimensions to 2 for visualization\n",
        "pca_subset = PCA(n_components=2)\n",
        "features_pca_subset = pca_subset.fit_transform(df_test_sub)\n",
        "\n",
        "# Adding the cluster labels to the subset dataframe\n",
        "df_test_sub['Cluster_3'] = kmeans_3.labels_\n",
        "\n",
        "# Plotting for k = 2 clusters\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(features_pca_subset[:, 0], features_pca_subset[:, 1], c=df_test_sub['Cluster_3'], cmap='viridis', marker='o', alpha=0.5)\n",
        "plt.title('K-means Clustering with k=3 (Selected Features)')\n",
        "plt.xlabel('PCA Feature 1')\n",
        "plt.ylabel('PCA Feature 2')\n",
        "plt.colorbar(label='Cluster Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2CR8DMdBOulr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract Cluster with label 0\n",
        "cluster_test_0=df_test_sub[df_test_sub['Cluster_3']==0]"
      ],
      "metadata": {
        "id": "VRjBI95AOzP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract Cluster with label 1\n",
        "cluster_test_1=df_test_sub[df_test_sub['Cluster_3']==1]"
      ],
      "metadata": {
        "id": "z2coTKOCO2ZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract Cluster with label 2\n",
        "cluster_test_2=df_test_sub[df_test_sub['Cluster_3']==2]"
      ],
      "metadata": {
        "id": "OrpJmxe-O5SC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Predictive Models on the Test Data"
      ],
      "metadata": {
        "id": "3tXrD462PYSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply Support Vector Regressor to get Median Household Incomes for cluster label 0\n",
        "cluster_test_svr=cluster_test_0.drop('Cluster_3',axis=1)\n",
        "y_pred=model_svr.predict(cluster_test_svr)\n",
        "cluster_test_0['Median Household Income (Current Year $)']=y_pred"
      ],
      "metadata": {
        "id": "wJkk54GgO7i8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply Random Forest to get Median Household Incomes for cluster label 1\n",
        "cluster_test_rf1=cluster_test_1.drop('Cluster_3',axis=1)\n",
        "y_pred1 = model_rf.predict(cluster_test_rf1)\n",
        "cluster_test_1['Median Household Income (Current Year $)']=y_pred1"
      ],
      "metadata": {
        "id": "6fiRtN_iPBqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply Random Forest to get Median Household Incomes for cluster label 2\n",
        "cluster_test_rf2=cluster_test_2.drop('Cluster_3',axis=1)\n",
        "y_pred2 = model_rf.predict(cluster_test_rf2)\n",
        "cluster_test_2['Median Household Income (Current Year $)']=y_pred2"
      ],
      "metadata": {
        "id": "QzxXcIpbPNB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Combine the clustered dataframes to get the Median Household Income for the entire test dataframe\n",
        "full_test_preds=pd.concat([cluster_test_0,cluster_test_1,cluster_test_2]).sort_index()"
      ],
      "metadata": {
        "id": "Kd8kfBvVPVMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert Median Household Income back to regular values from z-scores\n",
        "series_inc=(full_test_preds['Median Household Income (Current Year $)']*23524.348532) + 80443.679695\n",
        "full_test_preds['Median Household Income (Current Year $)']=series_inc"
      ],
      "metadata": {
        "id": "XBWIu29uPolp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the dataframe only for Median Household Income predictions\n",
        "preds_txt=pd.DataFrame(full_test_preds['Median Household Income (Current Year $)'])"
      ],
      "metadata": {
        "id": "ebLVG0SyPuL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get the predictions for Median Household Income in a text file format\n",
        "preds_txt.to_csv('Team15predictions.txt',sep=' ',index=False)"
      ],
      "metadata": {
        "id": "61nwW9OBPwWn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}